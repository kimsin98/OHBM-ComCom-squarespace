<p><span style="color:#000000; font-weight:400">By </span><a href="https://scholar.harvard.edu/tge"><span style="color:#1155cc; font-weight:400">Tian Ge</span></a><span style="color:#000000; font-weight:400">, </span><a href="https://yeolab.weebly.com/"><span style="color:#1155cc; font-weight:400">BT Thomas Yeo</span></a><span style="color:#000000; font-weight:400">, </span><a href="https://brainder.org/"><span style="color:#1155cc; font-weight:400">Anderson M Winkler</span></a></p>
<p><span style="color:#000000; font-weight:400">Permutation methods are a class of statistical tests that, under minimal assumptions, can provide exact control of false positives (i.e., type I error). The central assumption is simply that of exchangeability, that is, swapping data points keeps the data just as likely as the original. With the increasing availability of inexpensive large-scale computational resources and openly shared, large datasets, permutation methods are becoming popular in neuroimaging due to their flexibility and ease of concern about yielding nominal error rates than parametric tests, which rely on assumptions and/or approximations that may be difficult to meet in real data. This becomes even more important in the presence of multiple testing, in that assumptions may not be satisfied for each and every test, and the correlation across tests may be difficult to account for. However, even exchangeability can be violated in the presence of dependence among observations, and it may not always be clear what to permute. The aim of this blog post is to emphasize the relevance of linking the null hypothesis and the dependence structure within the data to what should be shuffled in a permutation test. We provide a few practical examples, and offer some glimpses of the theory along the way.</span></p>
<p><span style="color:#000000; font-weight:700">Example 1: Permutation mechanics</span></p>
<p><span style="color:#000000; font-weight:400">Let’s begin by reviewing the </span><a href="https://doi.org/10.1002/hbm.1058"><span style="color:#1155cc; font-weight:400">mechanics of a permutation test</span></a><span style="color:#000000; font-weight:400">. Consider a comparison between two groups, for example whether hippocampal volume is different between subjects with Alzheimer’s disease (AD) and demographically matched cognitively normal controls (that is, a group with similar age, sex, education level, etc). If we assume that in both groups the hippocampal volumes are independent samples from a Gaussian distribution, a classical parametric two-sample t-test can be used to test for a difference between means of the two groups. However, this distributional assumption may not be true, and departures from this assumption can potentially lead to incorrect conclusions. In these circumstances, permutation tests perform better than parametric tests by providing a valid statistical test with much weaker assumptions. Specifically, under the null hypothesis that the hippocampal volume has no actual difference between AD cases and controls, the group membership (or the label of case and control) becomes arbitrary, that is, any subject from one group might as well have been from the other.</span></p>
<p><span style="color:rgb(0, 0, 0)">While it may seem implausible that this would be the case for patients and controls, in fact this is what we are testing: all else being equal (that is, exchangeable), and any difference found must relate to the means, which is what we are interested in. In fact, a classical parametric two-sample test (with equal variance) makes not just the same assumption, but also further assumes that patients and controls come from the same Gaussian distribution. Permutation tests do not require Gaussianity; it suffices that the data are merely exchangeable. Exchangeability further relaxes another important assumption of parametric tests: independence. Data that are not independent may still be exchangeable, either globally or under certain restrictions, as presented in more detail in Example 3 below.</span></p>
<p><span style="color:rgb(0, 0, 0)">With exchangeability, we compute the t statistic under each permutation, and produce the permutation distribution of the statistic under the null. The permutation distribution is the empirical cumulative distribution function (cdf) obtained from the data themselves, as opposed to from some idealized distribution, as is the case with parametric tests. The observed test statistic can be considered a random sample from the permutation distribution because it is equally likely to have arisen from any case-control re-labeling given the null hypothesis.</span></p>
<p><span style="color:rgb(0, 0, 0)">The p-value is the probability of finding a test statistic for the group comparison at least as high as the one observed, provided that there is no actual difference (i.e., null hypothesis is true). So, the p-value can be calculated by randomly permuting the group labels many times, each time recalculating the test statistic; at the end of the process, we check how often a larger statistic was observed than the original (before any shuffling had been applied), and divide that by the number of permutations performed. Figure 1 shows an example in which there are three subjects in each group; before any permutation is done, the test statistic is t = +0.7361. After exhaustively computing all 20 possible permutations, we see that 4 of these (including the non-permuted) are higher than or equal to +0.7361. Thus, the p-value is 4/20 = 0.20. If we had decided beforehand that our significance level would be 0.05, we would say that the result of this test is not significant, that is, there is no significant difference in hippocampal volume between AD patients and controls.</span></p>
<p><span style="color:#000000; font-weight:700">Example 2: Permutation with the presence of nuisance</span></p>
<p><span style="color:#000000; font-weight:400">Suppose in Example 1 that there were other variables that could potentially explain some of the variability seen in hippocampal volume. Some of these variables could even be associated with diagnosis itself. For example, it may be the case that, in this particular study, AD patients were older than cognitively normal controls. To account for these nuisance variables, we can formulate the problem as a multiple regression, in which hippocampal volume is the dependent variable, whereas the case-control status, along with other potential nuisance variables, are the independent variables. We would then test whether the regression coefficient corresponding to the case-control label is significantly different than zero. Now it is less clear what should be permuted. If we permute just the group labels, what to do with the other variables in the model? It turns out that various approaches have been considered in the literature.</span></p>
<p><a href="https://doi.org/10.1016/j.neuroimage.2014.01.060"><span style="color:#1155cc; font-weight:400">Systematic evaluations</span></a><span style="color:#000000; font-weight:400"> show that, among a host of permutation and regression strategies, the method attributed to </span><a href="http://dx.doi.org/10.1080/07350015.1983.10509354"><span style="color:#1155cc; font-weight:400">Freedman and Lane</span></a><span style="color:#000000; font-weight:400"> provides accurate false positive control in the presence of nuisance variables and is robust to extreme outliers in the data. In the Freedman-Lane method, we regress out all nuisance variables from the hippocampal volume measurements to obtain the residuals of this nuisance-only model, and use the permuted residuals as the new dependent variable in the multiple regression, from which we construct the permutation distribution for the test statistic (i.e., the regression coefficient of interest). Intuitively, once the nuisance has been regressed out, what remains should be indistinguishable between AD patients and controls if the null hypothesis is true, and thus, can be permuted.</span></p>
<p><span style="color:#000000; font-weight:400">We note that whichever regression and permutation strategy is adopted, it is crucial that what is permuted is what would render the subjects different were the alternative hypothesis true. It is not relevant to permute aspects of the dataset that would not be affected should the null hypothesis be false, that is, should an effect actually exists. This is important because, when an experiment becomes complex (e.g., with multiple factors, levels, nuisance variables, and/or multiple response variables), it can be easy to permute aspects of the data that are not informative with respect to the null hypothesis. One should not lose sight of what is being tested, and permute the data accordingly.</span></p>
<p><span style="color:#000000; font-weight:700">Example 3: Permutation with the presence of dependence in observations</span></p>
<p><span style="color:#000000; font-weight:400">Data are </span><a href="https://doi.org/10.1016/j.neuroimage.2015.05.092"><span style="color:#1155cc; font-weight:400">not always freely exchangeable</span></a><span style="color:#000000; font-weight:400">. It may be the case, for example, that there are repeated measurements from the same subjects among the observations. Or maybe some or all subjects are twins, siblings, or otherwise relatives. Cases such as these restrict the possibilities for permutations, but even so, permutation tests continue to be possible. They proceed in a similar manner as in the examples above, but care needs to be taken when selecting the permutations that are allowed. Exchangeability as defined above — that is, permuting the data keeps them just as likely as originally observed — must be preserved. More technically, it means that the joint distribution of all the data points must remain unchanged under the null. For example, in a twin study, one could permute the subjects within twin pairs, and pairs of twins could be permuted as a whole, but one sibling should never be mixed with the sibling from a different family; see an example in Figure 2. These restrictions, unfortunately, tend to reduce power compared to the analyses in which all subjects are independent and freely exchangeable. However, all other benefits of permutation tests are kept.</span></p>
<p><span style="color:#000000; font-weight:400">Consider a longitudinal extension of the AD patients vs. controls example, in which two measurements are obtained from each subject, one before and another after an intervention is applied. As per above, the measurements must stay together within subject. However, depending on what is being tested, we may permute the data only within-subject, or only the subjects as a whole while keeping the order of intra-subject measurements unaltered, or do both things simultaneously. Within-subject effects (that is, the effect of treatment) would require that permutations happen within-subject, whereas between-subject effects would require permutations of the subjects as a whole. Interactions in a mixed design (within and between-subject effects) could benefit from both types of permutation. Crucially, what needs to be permuted is what would be equal should the null hypothesis hold, and that would differ should the alternative hypothesis be actually true.</span></p>
<p><span style="color:#000000; font-weight:700">Example 4: Comparison between models</span></p>
<p><span style="color:#000000; font-weight:400">Now suppose that, in our AD example, in addition to hippocampal volume, we have also measured the amygdala volume for each subject, and are interested in investigating whether hippocampal volume is a better biomarker of AD than amygdala volume (for example, in terms of standardized mean difference between cases and controls as measured by the Cohen’s d statistic). It is tempting to permute the case-control label, but this strategy turns out to be wrong as it completely breaks the associations between the hippocampal/amygdala volume and disease status, which should be retained under the null hypothesis. In fact, in this example, it is unclear what to permute. As a second example, if we want to test whether the mean of hippocampal volume in AD cases is significantly different from a fixed value (e.g., the typical size of hippocampus in normal aging subjects), it can be seen that there is nothing to permute. In these circumstances where a permutation test is difficult to apply, we need to resort to other methods such as </span><a href="https://www.crcpress.com/An-Introduction-to-the-Bootstrap/Efron-Tibshirani/p/book/9780412042317"><span style="color:#1155cc; font-weight:400">the bootstrap</span></a><span style="color:#000000; font-weight:400"> for statistical inference. </span></p>
<p><span style="color:#000000; font-weight:400">The bootstrap is an established data-based simulation method, which is often used to assign measures of accuracy, such as standard error, bias, and confidence intervals, to a statistical estimate. It essentially uses the observed data to define an empirical distribution that estimates the unknown underlying data-generation mechanism, and then generates bootstrap samples and bootstrap replications of the statistic of interest using the empirical distribution, from which measures of accuracy can be calculated. </span></p>
<p><span style="color:#000000; font-weight:400">Bootstrap can be applied to virtually any statistic and a wide variety of situations. For example, by sampling cases and controls with replacement independently, we can calculate the standard error or construct confidence intervals for the Cohen’s d statistic for hippocampal and amygdala volume, respectively, as well as for the difference of the two Cohen’s d. Given the strong connection between confidence intervals and hypothesis testing, a p-value can also be produced indicating whether the difference in Cohen’s d is significantly different from zero. In fact, bootstrap can be applied to hypothesis testing, including the questions described in Examples 1-3. However, unlike the permutation p-value, which is exact, the bootstrap significance is only approximate and thus less accurate.</span></p>
<p><span style="color:#000000; font-weight:400">Therefore, permutation is a natural and favorable choice when the null/alternative hypothesis is well defined and what to permute is clear. Bootstrap is useful when the primary goal is to quantify the accuracy of an estimate or when a permutation test is not available in a hypothesis test (e.g., nothing to permute). That said, we also caution that bootstrap relies on an accurate empirical estimation of the true underlying probability distribution. Thus the sampling procedure requires careful consideration in order to respect the data generation mechanism in the presence of complex data structures. For example, block bootstrap is often used to replicate correlations within the data, while variants of the wild bootstrap are used to capture heteroscedasticity in the sample.</span></p>
<p><span style="color:#000000; font-weight:700">Summary</span><ul><li style="color:#000000"><span style="color:#000000; font-weight:400">Permutation requires weak distributional assumptions that justify the exchangeabilityPermute what is exchangeable, and that would differ under the alternative hypothesis, while retaining other dependence structure in the data as much as possibleConsult statisticians when unsure about the permutation procedure</span></li></ul></p>
<p><strong>Practical advice:</strong> It's easy to get started with permutation methods in brain imaging. Most software packages have some sort of permutation test implemented. AFNI's <a href="https://afni.nimh.nih.gov/pub/dist/doc/program_help/3dttest++.html" target="_blank">3dttest++</a> now uses permutation by default for cluster inference with the -ClustSim option; BrainVoyager has a <a href="http://www.brainvoyager.com/bvresources/RainersBVBlog/files/a8a22212f9f1f01e4da11fef4ba91da8-34.html" target="_blank">randomisation plugin</a> (permutation tests are sometimes called randomisation tests); Freesurfer can do permutation with <a href="https://surfer.nmr.mgh.harvard.edu/fswiki/mri_glmfit" target="_blank">mri_glmfit-sim</a>; FSL has its <a href="https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/Randomise" target="_blank">randomise</a> tool; and SPM has the <a href="http://www.nisox.org/Software/SnPM" target="_blank">SnPM toolbox</a>. Finally, <a href="https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/PALM" target="_blank">PALM</a> is a standalone tool for permutation that works with different types of input data and has various advanced features.</p>
